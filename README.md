### kaggle-titanic

Repo for practicing machine learning using the Kaggle Titanic survival prediction competition

* Kaggle score for baseline implementation (no feature engineering, no regularization): 0.39234 (position 11,165)

* Kaggle score for implementation with regularization (no feature engineering): 0.44976 (position 11,162)


**Conclusion**

In this repo I took a short cut and used data cleaning code from users who posted these online (references are in the
source code). My goal was to focus on
the implementation of a cost function and of gradient descent as described in the Andrew NG Coursera Introduction to ML
course.
The scores I achieve are at the lower end which goes to show that the best algorithm will
not perform well unless considerable effort has gone into data cleaning and feature engineering!

.

