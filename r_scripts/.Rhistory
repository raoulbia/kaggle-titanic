for ( k in 1:K ) {
# split current replication training data into train/val
train_idx <- which(folds != k)
val_idx <- setdiff(1:N2, train_idx)
# fit random forests
fitrf <- randomForest(Survived ~ .,
data = Xtr,
subset = train_idx,
importance = T)
# validate random forests
predrf <- predict(fitrf,
type = "class",
newdata = Xtr[val_idx, ])
# compute accuracy and store result random forests
tabrf <- table(Xtr$Survived[val_idx], predrf)
acc[k, 1] <- sum(diag(tabrf))/sum(tabrf)
feat_imp_df <- importance(fitrf) %>%
data.frame() %>%
mutate(feature = row.names(.)) %>%
arrange(desc(MeanDecreaseAccuracy)) %>%
slice(1:3)
for (i in seq(1:3))
best_feature_tmp[k, i] <- feat_imp_df$feature[i]
} # END fold k
print(acc)
print(best_feature_tmp)
# avg k-folds
avg_k_folds <- apply(acc, 2, mean) # MARGIN=2, it works over columns
avg_k_folds <- c(`Random Forests` = avg_k_folds[1]) # add names
print(avg_k_folds)
# Predict X_te
predTestRf <- predict(fitrf,
type = "class",
newdata = Xte)
tabTestRf <- table(Xte$Survived, predTestRf)
accBest <- sum(diag(tabTestRf))/sum(tabTestRf)
accBest
Xtr[val_idx, ]
Xte
plot(fitrf)
# plot tree
reprtree:::plot.getTree(fitrf)
library(reprtree)
library(partyKit)
install.packages("partykit")
library(partyKit)
install.packages("partykit")
library(partyKit)
library(partykit)
# plot tree
plot(as.party(fitrf))
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
rm(list = ls())
library(tidyverse)
library(rio)
library(randomForest)
library(partykit)
options(digits=4, scipen=999)
# load data
data  <- import('../local-data/output/titanic_train_clean.csv', setclass = "tibble")
cols <- c("Survived", "Pclass", "Sex", "FamilySize", "hasCabin", "isChild")
dat <- data %>%
mutate_at(cols, factor)
dat$PassengerId <- NULL # remove original
head(dat)
#################
# Model fitting #
#################
# init params and data structures
set.seed(1238)
N <- nrow(dat)
# randomly split original data
train_idx <- sample(1:N, size = 0.75*N)
test_idx <- setdiff(1:N, train_idx)
Xtr <- dat[train_idx, ]
Xte <- dat[test_idx, ] # exclude from k-fold cross validation
# init folds
N2 <- nrow(Xtr)
K <- 10
folds <- rep( 1:K, ceiling(N2/K) )
folds <- sample(folds)             # random permute
folds <- folds[1:N2]                # ensure we got N data points
acc <- matrix(NA, K, 1) # for each fold store accuracy pairs
best_feature_tmp <- matrix(NA, K, 3) # store k best features for current replication
# k-fold cross validation
for ( k in 1:K ) {
# split current replication training data into train/val
train_idx <- which(folds != k)
val_idx <- setdiff(1:N2, train_idx)
# fit random forests
fitrf <- randomForest(Survived ~ .,
data = Xtr,
subset = train_idx,
plot importance = T)
# validate random forests
predrf <- predict(fitrf,
type = "class",
newdata = Xtr[val_idx, ])
# compute accuracy and store result random forests
tabrf <- table(Xtr$Survived[val_idx], predrf)
acc[k, 1] <- sum(diag(tabrf))/sum(tabrf)
feat_imp_df <- importance(fitrf) %>%
data.frame() %>%
mutate(feature = row.names(.)) %>%
arrange(desc(MeanDecreaseAccuracy)) %>%
slice(1:3)
for (i in seq(1:3))
best_feature_tmp[k, i] <- feat_imp_df$feature[i]
} # END fold k
print(acc)
print(best_feature_tmp)
# avg k-folds
avg_k_folds <- apply(acc, 2, mean) # MARGIN=2, it works over columns
avg_k_folds <- c(`Random Forests` = avg_k_folds[1]) # add names
print(avg_k_folds)
# Predict X_te
predTestRf <- predict(fitrf,
type = "class",
newdata = Xte[:, ])
tabTestRf <- table(Xte$Survived, predTestRf)
accBest <- sum(diag(tabTestRf))/sum(tabTestRf)
accBest
########
# Plot #
########
# Plot the error rates or MSE of rf object
plot(fitrf)
# plot tree
plot(as.party(fitrf))
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
rm(list = ls())
library(tidyverse)
library(rio)
library(randomForest)
library(partykit)
options(digits=4, scipen=999)
# load data
data  <- import('../local-data/output/titanic_train_clean.csv', setclass = "tibble")
cols <- c("Survived", "Pclass", "Sex", "FamilySize", "hasCabin", "isChild")
dat <- data %>%
mutate_at(cols, factor)
dat$PassengerId <- NULL # remove original
head(dat)
#################
# Model fitting #
#################
# init params and data structures
set.seed(1238)
N <- nrow(dat)
# randomly split original data
train_idx <- sample(1:N, size = 0.75*N)
test_idx <- setdiff(1:N, train_idx)
Xtr <- dat[train_idx, ]
Xte <- dat[test_idx, ] # exclude from k-fold cross validation
# init folds
N2 <- nrow(Xtr)
K <- 10
folds <- rep( 1:K, ceiling(N2/K) )
folds <- sample(folds)             # random permute
folds <- folds[1:N2]                # ensure we got N data points
acc <- matrix(NA, K, 1) # for each fold store accuracy pairs
best_feature_tmp <- matrix(NA, K, 3) # store k best features for current replication
# k-fold cross validation
for ( k in 1:K ) {
# split current replication training data into train/val
train_idx <- which(folds != k)
val_idx <- setdiff(1:N2, train_idx)
# fit random forests
fitrf <- randomForest(Survived ~ .,
data = Xtr,
subset = train_idx,
importance = T)
# validate random forests
predrf <- predict(fitrf,
type = "class",
newdata = Xtr[val_idx, ])
# compute accuracy and store result random forests
tabrf <- table(Xtr$Survived[val_idx], predrf)
acc[k, 1] <- sum(diag(tabrf))/sum(tabrf)
feat_imp_df <- importance(fitrf) %>%
data.frame() %>%
mutate(feature = row.names(.)) %>%
arrange(desc(MeanDecreaseAccuracy)) %>%
slice(1:3)
for (i in seq(1:3))
best_feature_tmp[k, i] <- feat_imp_df$feature[i]
} # END fold k
print(acc)
print(best_feature_tmp)
# avg k-folds
avg_k_folds <- apply(acc, 2, mean) # MARGIN=2, it works over columns
avg_k_folds <- c(`Random Forests` = avg_k_folds[1]) # add names
print(avg_k_folds)
# Predict X_te
predTestRf <- predict(fitrf,
type = "class",
newdata = Xte[:, ])
tabTestRf <- table(Xte$Survived, predTestRf)
accBest <- sum(diag(tabTestRf))/sum(tabTestRf)
accBest
########
# Plot #
########
# Plot the error rates or MSE of rf object
plot(fitrf)
# plot tree
plot(as.party(fitrf))
# plot tree
getTree(fitrf, 1, labelVar=TRUE)
options(repos='http://cran.rstudio.org')
have.packages <- installed.packages()
cran.packages <- c('devtools','plotrix','randomForest','tree')
to.install <- setdiff(cran.packages, have.packages[,1])
if(length(to.install)>0) install.packages(to.install)
library(devtools)
if(!('reprtree' %in% installed.packages())){
install_github('araastat/reprtree')
}
for(p in c(cran.packages, 'reprtree')) eval(substitute(library(pkg), list(pkg=p)))
options(repos='http://cran.rstudio.org')
have.packages <- installed.packages()
cran.packages <- c('devtools','plotrix','randomForest','tree')
to.install <- setdiff(cran.packages, have.packages[,1])
if(length(to.install)>0) install.packages(to.install)
library(devtools)
if(!('reprtree' %in% installed.packages())){
install_github('araastat/reprtree')
}
for(p in c(cran.packages, 'reprtree')) eval(substitute(library(pkg), list(pkg=p)))
library(reprtree)
# plot tree
tree <- getTree(fitrf, 1, labelVar=TRUE)
d <- to.dendrogram(tree)
to.dendrogram <- function(dfrep,rownum=1,height.increment=0.1){
if(dfrep[rownum,'status'] == -1){
rval <- list()
attr(rval,"members") <- 1
attr(rval,"height") <- 0.0
attr(rval,"label") <- dfrep[rownum,'prediction']
attr(rval,"leaf") <- TRUE
}else{##note the change "to.dendrogram" and not "to.dendogram"
left <- to.dendrogram(dfrep,dfrep[rownum,'left daughter'],height.increment)
right <- to.dendrogram(dfrep,dfrep[rownum,'right daughter'],height.increment)
rval <- list(left,right)
attr(rval,"members") <- attr(left,"members") + attr(right,"members")
attr(rval,"height") <- max(attr(left,"height"),attr(right,"height")) + height.increment
attr(rval,"leaf") <- FALSE
attr(rval,"edgetext") <- dfrep[rownum,'split var']
#To add Split Point in Dendrogram
#attr(rval,"edgetext") <- paste(dfrep[rownum,'split var'],"\n<",round(dfrep[rownum,'split point'], digits = 2),"=>", sep = " ")
}
class(rval) <- "dendrogram"
return(rval)
}
d <- to.dendrogram(tree)
str(d)
plot(d,center=TRUE,leaflab='none',edgePar=list(t.cex=1,p.col=NA,p.lty=0))
else {colnames(fitrf$test$err.rate)}
fitrf <- if (is.null(fitrf$test$err.rate)
{colnames(fitrf$err.rate)}
else {colnames(fitrf$test$err.rate)})
{colnames(fitrf$test$err.rate)}
fitrf <- ifelse( is.null(fitrf$test$err.rate), colnames(fitrf$err.rate), colnames(fitrf$test$err.rate) )
legend("top", cex =0.5, legend=fitrf.legend, lty=c(1,2,3), col=c(1,2,3), horiz=T)
fitrf.legend <- ifelse( is.null(fitrf$test$err.rate), colnames(fitrf$err.rate), colnames(fitrf$test$err.rate) )
# Plot the error rates or MSE of rf object
plot(fitrf)
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
rm(list = ls())
library(tidyverse)
library(rio)
library(randomForest)
library(reprtree)
options(digits=4, scipen=999)
# load data
data  <- import('../local-data/output/titanic_train_clean.csv', setclass = "tibble")
cols <- c("Survived", "Pclass", "Sex", "FamilySize", "hasCabin", "isChild")
dat <- data %>%
mutate_at(cols, factor)
dat$PassengerId <- NULL # remove original
head(dat)
#################
# Model fitting #
#################
# init params and data structures
set.seed(1238)
N <- nrow(dat)
# randomly split original data
train_idx <- sample(1:N, size = 0.75*N)
test_idx <- setdiff(1:N, train_idx)
Xtr <- dat[train_idx, ]
Xte <- dat[test_idx, ] # exclude from k-fold cross validation
# init folds
N2 <- nrow(Xtr)
K <- 10
folds <- rep( 1:K, ceiling(N2/K) )
folds <- sample(folds)             # random permute
folds <- folds[1:N2]                # ensure we got N data points
acc <- matrix(NA, K, 1) # for each fold store accuracy pairs
best_feature_tmp <- matrix(NA, K, 3) # store k best features for current replication
# k-fold cross validation
for ( k in 1:K ) {
# split current replication training data into train/val
train_idx <- which(folds != k)
val_idx <- setdiff(1:N2, train_idx)
# fit random forests
fitrf <- randomForest(Survived ~ .,
data = Xtr,
subset = train_idx,
importance = T)
# validate random forests
predrf <- predict(fitrf,
type = "class",
newdata = Xtr[val_idx, ])
# compute accuracy and store result random forests
tabrf <- table(Xtr$Survived[val_idx], predrf)
acc[k, 1] <- sum(diag(tabrf))/sum(tabrf)
feat_imp_df <- importance(fitrf) %>%
data.frame() %>%
mutate(feature = row.names(.)) %>%
arrange(desc(MeanDecreaseAccuracy)) %>%
slice(1:3)
for (i in seq(1:3))
best_feature_tmp[k, i] <- feat_imp_df$feature[i]
} # END fold k
print(acc)
print(best_feature_tmp)
# avg k-folds
avg_k_folds <- apply(acc, 2, mean) # MARGIN=2, it works over columns
avg_k_folds <- c(`Random Forests` = avg_k_folds[1]) # add names
print(avg_k_folds)
# Predict X_te
predTestRf <- predict(fitrf,
type = "class",
newdata = Xte[:, ])
tabTestRf <- table(Xte$Survived, predTestRf)
accBest <- sum(diag(tabTestRf))/sum(tabTestRf)
accBest
########
# Plot #
########
# Predict X_te
predTestRf <- predict(fitrf,
type = "class",
newdata = Xte)
tabTestRf <- table(Xte$Survived, predTestRf)
accBest <- sum(diag(tabTestRf))/sum(tabTestRf)
accBest
# Plot the error rates or MSE of rf object
plot(fitrf)
fitrf.legend <- ifelse( is.null(fitrf$test$err.rate), colnames(fitrf$err.rate), colnames(fitrf$test$err.rate) )
legend("top", cex =0.5, legend=fitrf.legend, lty=c(1,2,3), col=c(1,2,3), horiz=T)
pt <- prettytree(fitrf@ensemble[[1]], names(cf@data@get("input")))
library(party)
library(partykit)
pt <- prettytree(fitrf@ensemble[[1]], names(cf@data@get("input")))
install.packages("party")
library(party)
pt <- prettytree(fitrf@ensemble[[1]], names(cf@data@get("input")))
pt <- prettytree(fitrf$ensemble[[1]], names(cf$data$get("input")))
itrf$ensemble[[1]]
fitrf$ensemble[[1]]
install.packages("randomForestExplainer")
library(randomForestExplainer)
library(party)
# plot tree
party:::prettytree(fitrf)
# plot tree
party:::prettytree(fitrf$type)
# plot tree
getTree(fitrf, k=1, labelVar=FALSE)
# plot tree
getTree(fitrf, k=1, labelVar=FALSE) %>%
tibble::rownames_to_column() %>%
# make leaf split points to NA, so the 0s won't get plotted
mutate(`split point` = ifelse(is.na(prediction), `split point`, NA))
# plot tree
getTree(fitrf, k=1, labelVar=FALSE) %>%
tibble::rownames_to_column(.) %>%
# make leaf split points to NA, so the 0s won't get plotted
mutate(`split point` = ifelse(is.na(prediction), `split point`, NA))
fitrf <- as.data.frame(fitrf) %>%
getTree(fitrf, k=1, labelVar=FALSE) %>%
tibble::rownames_to_column() %>%
# make leaf split points to NA, so the 0s won't get plotted
mutate(`split point` = ifelse(is.na(prediction), `split point`, NA))
fitrf
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
rm(list = ls())
library(tidyverse)
library(rio)
library(randomForest)
library(party)
options(digits=4, scipen=999)
# load data
data  <- import('../local-data/output/titanic_train_clean.csv', setclass = "tibble")
cols <- c("Survived", "Pclass", "Sex", "FamilySize", "hasCabin", "isChild")
dat <- data %>%
mutate_at(cols, factor)
dat$PassengerId <- NULL # remove original
head(dat)
#################
# Model fitting #
#################
# init params and data structures
set.seed(1238)
N <- nrow(dat)
# randomly split original data
train_idx <- sample(1:N, size = 0.75*N)
test_idx <- setdiff(1:N, train_idx)
Xtr <- dat[train_idx, ]
Xte <- dat[test_idx, ] # exclude from k-fold cross validation
# init folds
N2 <- nrow(Xtr)
K <- 10
folds <- rep( 1:K, ceiling(N2/K) )
folds <- sample(folds)             # random permute
folds <- folds[1:N2]                # ensure we got N data points
acc <- matrix(NA, K, 1) # for each fold store accuracy pairs
best_feature_tmp <- matrix(NA, K, 3) # store k best features for current replication
# k-fold cross validation
for ( k in 1:K ) {
# split current replication training data into train/val
train_idx <- which(folds != k)
val_idx <- setdiff(1:N2, train_idx)
# fit random forests
fitrf <- randomForest(Survived ~ .,
data = Xtr,
subset = train_idx,
importance = T)
# validate random forests
predrf <- predict(fitrf,
type = "class",
newdata = Xtr[val_idx, ])
# compute accuracy and store result random forests
tabrf <- table(Xtr$Survived[val_idx], predrf)
acc[k, 1] <- sum(diag(tabrf))/sum(tabrf)
feat_imp_df <- importance(fitrf) %>%
data.frame() %>%
mutate(feature = row.names(.)) %>%
arrange(desc(MeanDecreaseAccuracy)) %>%
slice(1:3)
for (i in seq(1:3))
best_feature_tmp[k, i] <- feat_imp_df$feature[i]
} # END fold k
print(acc)
print(best_feature_tmp)
# avg k-folds
avg_k_folds <- apply(acc, 2, mean) # MARGIN=2, it works over columns
avg_k_folds <- c(`Random Forests` = avg_k_folds[1]) # add names
print(avg_k_folds)
# Predict X_te
predTestRf <- predict(fitrf,
type = "class",
newdata = Xte)
tabTestRf <- table(Xte$Survived, predTestRf)
accBest <- sum(diag(tabTestRf))/sum(tabTestRf)
accBest
fitrf
T_te
# load data
titanic_test_data  <- import('../local-data/output/titanic_train_clean.csv', setclass = "tibble")
cols <- c("Pclass", "Sex", "FamilySize", "hasCabin", "isChild")
T_te <- titanic_test_data %>%
mutate_at(cols, factor)
T_te$PassengerId <- NULL # remove original
head(T_te)
T_te
# load data
titanic_test_data  <- import('../local-data/output/titanic_train_clean.csv', setclass = "tibble")
titanic_test_data
# load data
titanic_test_data  <- import('../local-data/output/titanic_test_clean', setclass = "tibble")
# load data
titanic_test_data  <- import('../local-data/output/titanic_test_clean.csv', setclass = "tibble")
cols <- c("Pclass", "Sex", "FamilySize", "hasCabin", "isChild")
T_te <- titanic_test_data %>%
mutate_at(cols, factor)
T_te$PassengerId <- NULL # remove original
head(T_te)
predTitanicTestRf <- predict(fitrf,
type = "class",
newdata = T_te)
predTitanicTestRf
c(T_te$PassengerId , predTitanicTestRf)
# load data
titanic_test_data  <- import('../local-data/output/titanic_test_clean.csv', setclass = "tibble")
cols <- c("Pclass", "Sex", "FamilySize", "hasCabin", "isChild")
T_te <- titanic_test_data %>%
mutate_at(cols, factor)
head(T_te)
T_te[:, 1:]
T_te[, -1]
predTitanicTestRf <- predict(fitrf,
type = "class",
newdata = T_te[, -1])
c(T_te$PassengerId , predTitanicTestRf)
T_te$PassengerId
c(T_te$PassengerId , predTitanicTestRf)
T_te$Survived <- predTitanicTestRf <- predict(fitrf,
type = "class",
newdata = T_te[, -1])
T_te
submission <- T_te %>% select(PassengerId, Survived)
write.csv(submission, "'../local-data/output/submission.csv", row.names = FALSE)
cwd
pwd
write.csv(submission, "../local-data/output/submission.csv", row.names = FALSE)
