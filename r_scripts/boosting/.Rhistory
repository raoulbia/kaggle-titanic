interaction.depth = 3,
# n.minobsinnode = 10,
n.trees = 100,
# shrinkage = 0.001,
train.fraction = 0.8,
# verbose = TRUE
)
# par(mfrow=c(1,2))
gbm.perf(fit)
fit <- gbm(Survived ~ .,
data=dat[train_idx,],
distribution = "bernoulli",
interaction.depth = 3,
# n.minobsinnode = 10,
n.trees = 100,
# shrinkage = 0.001,
train.fraction = 0.8,
verbose = TRUE
)
# dat <- dat[sample(nrow(dat), 50), ]
head(dat)
# boosting
# look at the effect of options: coeflearn, boos, etc.
fit <- boosting(Survived ~. ,
data = dat[train_idx,],
coeflearn = "Freund",
boos = TRUE,
# mfinal = 1,
# control=rpart.control(maxdepth=3)
)
# boosting
# look at the effect of options: coeflearn, boos, etc.
fit <- boosting(Survived ~. ,
data = dat[train_idx,],
coeflearn = "Breimann",
boos = TRUE,
# mfinal = 1,
# control=rpart.control(maxdepth=3)
)
# boosting
# look at the effect of options: coeflearn, boos, etc.
fit <- boosting(Survived ~. ,
data = dat[train_idx,],
coeflearn = "Breiman",
boos = TRUE,
mfinal = 1,
# control=rpart.control(maxdepth=3)
)
source('C:/Users/BIAGIONIR/vmtest/kaggle-titanic/r_scripts/boosting/test_boosting.R', echo=TRUE)
# boosting
# look at the effect of options: coeflearn, boos, etc.
fit <- boosting(Survived ~Sex+Pclass ,
data = dat[train_idx,],
coeflearn = "Breiman",
boos = TRUE,
mfinal = 1,
# control=rpart.control(maxdepth=3)
)
library(caret)
library(caret)
fit <- train(train$survived~., data=dat[train_idx,, method="gbm", distribution="bernoulli")
fit <- train(train$survived~., data=dat[train_idx,], method="gbm", distribution="bernoulli")
fit <- train(Survived~., data=dat[train_idx,], method="gbm", distribution="bernoulli")
#                data=dat[train_idx,],
#                distribution = "bernoulli",
#                interaction.depth = 3,
#                # n.minobsinnode = 10,
#                n.trees = 100,
#                # shrinkage = 0.001,
#                train.fraction = 0.8,
#                verbose = TRUE
#                )
# # par(mfrow=c(1,2))
gbm.perf(fit)
fit <- train(Survived~., data=dat[train_idx,],
method="adaboost",
# distribution="bernoulli"
)
fit <- train(Survived~., data=dat[train_idx,],
methdd="adaboost",
niter=10
# distribution="bernoulli"
)
fit
fit <- train(Survived~., data=dat[train_idx,],
methdd="adaboost",
niter=100
# distribution="bernoulli"
)
fit
err_train <- errorevol(fit, dat[train,])$error
#                distribution = "bernoulli",
#                interaction.depth = 3,
#                # n.minobsinnode = 10,
#                n.trees = 100,
#                # shrinkage = 0.001,
#                train.fraction = 0.8,
#                verbose = TRUE
#                )
# # par(mfrow=c(1,2))
# gbm.perf(fit)
trellis.par.set(caretTheme())
plot(gbmFit2)
plot(fit)
predict(fit, newdata = head(dat[val,]))
dat[val_idx,]
head(dat[val_idx,])
predict(fit, newdata = dat[val_idx,])
# boosting
# look at the effect of options: coeflearn, boos, etc.
fit <- boosting(Survived ~Sex+Pclass ,
data = dat[train_idx,],
coeflearn = "Breiman",
boos = TRUE,
mfinal = 1,
# control=rpart.control(maxdepth=3)
)
fit <- train(Survived~., data=dat[train_idx,],
methdd="adaboost",
niter=100
# distribution="bernoulli"
)
fit <- train(Survived~., data=dat[train_idx,],
methdd="adaboost",
niter=100
)
fit <- train(Survived~., data=dat[train_idx,],
methdd="adaboost",
niter=5000
)
fit
# predict on validation data
predval <- predict(fit, newdata = dat[val_idx,])
predval
dat[val_idx,]
table(dat$Survived[val_idx], predval)
tab <- table(dat$Survived[val_idx], predval)
sum(diag(tab))/sum(tab)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
rm(list = ls())
#############
# load data #
#############
data  <- import('../../local-data/output/titanic_train_clean.csv', setclass = "tibble")
cols <- c("Survived", "Pclass", "Sex", "FamilySize", "hasCabin", "isChild")
dat <- data %>%
mutate_if(is.double, as.integer)
# mutate_at(cols, as.numeric(factor))
dat$PassengerId <- NULL # remove original
dat$Survived <- as.factor(dat$Survived)
# dat <- dat[sample(nrow(dat), 50), ]
head(dat)
# TODO is scaling applicable here? don't think so
##############
# Split Data #
##############
# init params and data structures
set.seed(1238)
# dat[,-1] <- scale(dat[,-1])  # standardize
# split data into training, validation and test
N <- nrow(dat)
train_idx <- sort( sample(1:N, size = N*0.7) )
val_idx <- setdiff(1:N, train_idx)
# boosting
fit <- train(Survived~., data=dat[train_idx,],
methdd="adaboost",
niter=5000
)
fit
trellis.par.set(caretTheme())
# plotting
plot(fit)
# predict on validation data
predval <- predict(fit, newdata = dat[val_idx,])
predval
tab <- table(dat$Survived[val_idx], predval)
sum(diag(tab))/sum(tab)
# load data
titanic_test_data  <- import('../../local-data/output/titanic_test_clean.csv', setclass = "tibble")
T_te <- data %>%
mutate_if(is.double, as.integer)
head(T_te)
T_te$Survived <- predTitanicTestRf <- predict(fit,
type = "class",
newdata = T_te[, -1])
T_te$Survived <- predTitanicTestRf <- predict(fit,
newdata = T_te[, -1])
titanic_test_data  <- import('../../local-data/output/titanic_test_clean.csv', setclass = "tibble")
T_te <- titanic_test_data %>%
mutate_if(is.double, as.integer)
head(T_te)
T_te$Survived <- predTitanicTestRf <- predict(fit,
newdata = T_te[, -1])
T_te$Survived
submission <- T_te %>% select(PassengerId, Survived)
T_te
submission <- T_te %>% select(PassengerId, Survived)
submission <- T_te %>% dplyr::select(PassengerId, Survived)
currentDate <- Sys.Date()
csvFileName <- paste("../../local-data/output/submission_",currentDate,".csv",sep="")
write.csv(submission, csvFileName, row.names = FALSE)
fit
# boosting
fit <- train(Survived~., data=dat[train_idx,],
method="adaboost",
niter=5000
)
fit
# plotting
plot(fit)
summary(fit)
# predict on validation data
predval <- predict(fit, newdata = dat[val_idx,])
tab <- table(dat$Survived[val_idx], predval)
sum(diag(tab))/sum(tab)
# Setup grid search
ctrl <- trainControl(method = "boot",
number=25, # resampling iterations
selectionFunction = "Accuracy"
)
# boosting
fit <- train(Survived~., data=dat[train_idx,],
method="adaboost",
# niter=5000,
trControl=ctrl
)
# Setup grid search
ctrl <- trainControl(method = "boot",
number=25, # resampling iterations
selectionFunction = "oneSE"
)
# boosting
fit <- train(Survived~., data=dat[train_idx,],
method="adaboost",
# niter=5000,
trControl=ctrl
)
fit
# plotting
plot(fit)
summary(fit)
# Setup grid search
ctrl <- trainControl(method="repeatedcv",
number=10,
repeats=5,
selectionFunction = "oneSE"
)
# boosting
fit <- train(Survived~., data=dat[train_idx,],
method="adaboost",
# niter=5000,
trControl=ctrl
)
fit; #summary(fit)
# plotting
plot(fit)
# predict on validation data
predval <- predict(fit, newdata = dat[val_idx,])
tab <- table(dat$Survived[val_idx], predval)
sum(diag(tab))/sum(tab)
# load data
titanic_test_data  <- import('../../local-data/output/titanic_test_clean.csv', setclass = "tibble")
T_te <- titanic_test_data %>%
mutate_if(is.double, as.integer)
T_te
T_te$Survived <- predict(fit,
newdata = T_te[, -1] # rm PassengerId
)
submission <- T_te %>% dplyr::select(PassengerId, Survived)
currentDate <- Sys.Date()
csvFileName <- paste("../../local-data/output/submission_",currentDate,".csv",sep="")
write.csv(submission, csvFileName, row.names = FALSE)
install.packages("doParallel")
library(lattice)  # for plotting
## Run all subsequent models in parallel
library(doParallel)
cl <- makePSOCKcluster(5)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
rm(list = ls())
#############
# load data #
#############
data  <- import('../../local-data/output/titanic_train_clean.csv', setclass = "tibble")
cols <- c("Survived", "Pclass", "Sex", "FamilySize", "hasCabin", "isChild")
dat <- data %>%
mutate_if(is.double, as.integer)
# mutate_at(cols, as.numeric(factor))
dat$PassengerId <- NULL # remove original
dat$Survived <- as.factor(dat$Survived)
# dat <- dat[sample(nrow(dat), 50), ]
head(dat)
# TODO is scaling applicable here? don't think so
##############
# Split Data #
##############
# init params and data structures
set.seed(1238)
# dat[,-1] <- scale(dat[,-1])  # standardize
# split data into training, validation and test
N <- nrow(dat)
train_idx <- sort( sample(1:N, size = N*0.7) )
val_idx <- setdiff(1:N, train_idx)
# randomly split into test and validation
# SKIP THIS AS WE DONT DO MODEL SELECTION HERE
# test_idx <- sort( sample(val_idx, length(val_idx)/2) )
# val_idx <- setdiff(val_idx, test_idx)
# length(train_idx)+length(test_idx)+length(val_idx) # sanity check
# Setup grid search
ctrl <- trainControl(method="repeatedcv", number=10, repeats=5)
rf.fit        <- train(cd~., data=dat[train_idx,], method="rf", trControl=control);
knn.fit       <- train(cd~., data=dat[train_idx,], method="knn", trControl=control);
svm.fit       <- train(cd~., data=dat[train_idx,], method="svmRadialWeights", trControl=control);
adabag.fit    <- train(cd~., data=dat[train_idx,], method="AdaBag", trControl=control);
adaboost.fit  <- train(cd~., data=dat[train_idx,], method="adaboost", trControl=control)
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
rm(list = ls())
library(xgboost)
library(caret)
trellis.par.set(caretTheme())
library(lattice)  # for plotting
## Run all subsequent models in parallel
library(doParallel)
cl <- makePSOCKcluster(5)
data  <- import('../../local-data/output/titanic_train_clean.csv', setclass = "tibble")
cols <- c("Survived", "Pclass", "Sex", "FamilySize", "hasCabin", "isChild")
library(rio)
install_formats()
data  <- import('../../local-data/output/titanic_train_clean.csv', setclass = "tibble")
cols <- c("Survived", "Pclass", "Sex", "FamilySize", "hasCabin", "isChild")
dat <- data %>%
mutate_if(is.double, as.integer)
library(dplyr) # for piping
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
rm(list = ls())
library(xgboost)
library(caret)
trellis.par.set(caretTheme())
library(lattice)  # for plotting
library(rio) # for importing data
library(dplyr) # for piping
## Run all subsequent models in parallel
library(doParallel)
cl <- makePSOCKcluster(5)
data  <- import('../../local-data/output/titanic_train_clean.csv', setclass = "tibble")
cols <- c("Survived", "Pclass", "Sex", "FamilySize", "hasCabin", "isChild")
dat <- data %>%
mutate_if(is.double, as.integer)
dat$PassengerId <- NULL # remove original
dat$Survived <- as.factor(dat$Survived)
# dat <- dat[sample(nrow(dat), 50), ]
head(dat)
# init params and data structures
set.seed(1238)
# split data into training, validation and test
N <- nrow(dat)
train_idx <- sort( sample(1:N, size = N*0.7) )
val_idx <- setdiff(1:N, train_idx)
# Setup grid search
ctrl <- trainControl(method="repeatedcv", number=10, repeats=5)
rf.fit        <- train(cd~., data=dat[train_idx,], method="rf", trControl=control);
rf.fit        <- train(Survived~., data=dat[train_idx,], method="rf", trControl=control);
knn.fit       <- train(Survived~., data=dat[train_idx,], method="knn", trControl=control);
svm.fit       <- train(Survived~., data=dat[train_idx,], method="svmRadialWeights", trControl=control);
# Setup grid search
ctrl <- trainControl(method="repeatedcv", number=10, repeats=5)
rf.fit        <- train(Survived~., data=dat[train_idx,], method="rf", trControl=control);
rf.fit        <- train(Survived~., data=dat[train_idx,], method="rf", trControl=ctrl);
knn.fit       <- train(Survived~., data=dat[train_idx,], method="knn", trControl=ctrl);
svm.fit       <- train(Survived~., data=dat[train_idx,], method="svmRadialWeights", trControl=ctrl);
adabag.fit    <- train(Survived~., data=dat[train_idx,], method="AdaBag", trControl=ctrl);
adaboost.fit  <- train(Survived~., data=dat[train_idx,], method="adaboost", trControl=ctrl)
n.cores <- detectCores(all.tests = T, logical = T)
n.cores
cl <- makePSOCKcluster(n.cores)
doParallel::registerDoParallel(cl)
rf.fit
knn.fit
svm.fit
adaboost.fit  <- train(Survived~., data=dat[train_idx,], method="adaboost", trControl=ctrl)
# plotting
plot(fit)
adabag.fit
adaboost.fit
# summary of model differences
results <- resamples(list(RF=rf.fit, kNN=knn.fit, SVM=svm.fit,
Bag=adabag.fit,
Boost=adaboost.fit))
summary(results)
# Plot Accuracy Summaries
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results, scales=scales)                 # Box plots of accuracy
# Predict on validation data
predval <- predict(adabag.fit, newdata = dat[val_idx,])
tab <- table(dat$Survived[val_idx], predval)
sum(diag(tab))/sum(tab)
# Predict on validation data
predval <- predict(rf.fit, newdata = dat[val_idx,])
tab <- table(dat$Survived[val_idx], predval)
sum(diag(tab))/sum(tab)
titanic_test_data  <- import('../../local-data/output/titanic_test_clean.csv', setclass = "tibble")
T_te <- titanic_test_data %>%
mutate_if(is.double, as.integer)
head(T_te)
T_te$Survived <- predict(fit,
newdata = T_te[, -1] # rm PassengerId
)
submission <- T_te %>% dplyr::select(PassengerId, Survived)
currentDate <- Sys.Date()
csvFileName <- paste("../../local-data/output/submission_",currentDate,".csv",sep="")
write.csv(submission, csvFileName, row.names = FALSE)
T_te$Survived <- predict(rf.fit,
newdata = T_te[, -1] # rm PassengerId
)
submission <- T_te %>% dplyr::select(PassengerId, Survived)
currentDate <- Sys.Date()
csvFileName <- paste("../../local-data/output/submission_",currentDate,".csv",sep="")
write.csv(submission, csvFileName, row.names = FALSE)
dat
res <- cor(dat[:, -1])
res <- cor(dat[, -1])
round(res, 2)
dat$hasCabin <- NULL # high correlation with Pclass
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
rm(list = ls())
library(xgboost)
library(caret)
trellis.par.set(caretTheme())
library(lattice)  # for plotting
library(rio) # for importing data
library(dplyr) # for piping
# Run all subsequent models in parallel
# library(doParallel)
# n.cores <- detectCores(all.tests = T, logical = T)
# cl <- makePSOCKcluster(n.cores)
# doParallel::registerDoParallel(cl)
#############
# load data #
#############
data  <- import('../../local-data/output/titanic_train_clean.csv', setclass = "tibble")
cols <- c("Survived", "Pclass", "Sex", "FamilySize", "hasCabin", "isChild")
dat <- data %>%
mutate_if(is.double, as.integer)
# mutate_at(cols, as.numeric(factor))
dat$PassengerId <- NULL # remove original
dat$hasCabin <- NULL # high correlation with Pclass
dat$Survived <- as.factor(dat$Survived)
# dat <- dat[sample(nrow(dat), 50), ]
head(dat)
# TODO is scaling applicable here? don't think so
res <- cor(dat[, -1])
round(res, 2)
set.seed(1238)
# dat[,-1] <- scale(dat[,-1])  # standardize
# split data into training, validation and test
N <- nrow(dat)
train_idx <- sort( sample(1:N, size = N*0.7) )
val_idx <- setdiff(1:N, train_idx)
# Setup grid search
ctrl <- trainControl(method="repeatedcv", number=10, repeats=5)
system.time({
rf.fit        <- train(Survived~., data=dat[train_idx,], method="rf", trControl=ctrl);
knn.fit       <- train(Survived~., data=dat[train_idx,], method="knn", trControl=ctrl);
svm.fit       <- train(Survived~., data=dat[train_idx,], method="svmRadialWeights", trControl=ctrl);
adabag.fit    <- train(Survived~., data=dat[train_idx,], method="AdaBag", trControl=ctrl); # SLOW
adaboost.fit  <- train(Survived~., data=dat[train_idx,], method="adaboost", trControl=ctrl)
})
# summary of model differences
results <- resamples(list(RF=rf.fit, kNN=knn.fit, SVM=svm.fit,
Bag=adabag.fit,
Boost=adaboost.fit))
summary(results)
# Plot Accuracy Summaries
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(results, scales=scales)                 # Box plots of accuracy
predval <- predict(rf.fit, newdata = dat[val_idx,])
tab <- table(dat$Survived[val_idx], predval)
sum(diag(tab))/sum(tab)
predval <- predict(svm.fit, newdata = dat[val_idx,])
tab <- table(dat$Survived[val_idx], predval)
sum(diag(tab))/sum(tab)
predval <- predict(adabag.fit, newdata = dat[val_idx,])
tab <- table(dat$Survived[val_idx], predval)
sum(diag(tab))/sum(tab)
# load data
titanic_test_data  <- import('../../local-data/output/titanic_test_clean.csv', setclass = "tibble")
T_te <- titanic_test_data %>%
mutate_if(is.double, as.integer)
head(T_te)
T_te$Survived <- predict(svm.fit,
newdata = T_te[, -1] # rm PassengerId
)
submission <- T_te %>% dplyr::select(PassengerId, Survived)
currentDate <- Sys.Date()
csvFileName <- paste("../../local-data/output/submission_",currentDate,".csv",sep="")
write.csv(submission, csvFileName, row.names = FALSE)
rf.fit        <- train(Survived~Sex+FamilySize, data=dat[train_idx,], method="rf", trControl=ctrl);
rf.fit
predval <- predict(rf.fit, newdata = dat[val_idx,])
tab <- table(dat$Survived[val_idx], predval)
sum(diag(tab))/sum(tab)
train_idx <- sort( sample(1:N, size = N*0.8) )
val_idx <- setdiff(1:N, train_idx)
rf.fit        <- train(Survived~Sex+FamilySize, data=dat[train_idx,], method="rf", trControl=ctrl);
rf.fit
rf.fit        <- train(Survived~Sex+Pclass+Age2, data=dat[train_idx,], method="rf", trControl=ctrl);
rf.fit
predval <- predict(rf.fit, newdata = dat[val_idx,])
tab <- table(dat$Survived[val_idx], predval)
sum(diag(tab))/sum(tab)
